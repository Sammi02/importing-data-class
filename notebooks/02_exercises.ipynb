{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50567591",
   "metadata": {},
   "source": [
    "# Student Exercises: Importing Data\n",
    "\n",
    "Work in pairs. Complete the TODOs below. Aim for 10–15 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, json\n",
    "BASE = Path().resolve().parents[1] if (Path().resolve().name == \"notebooks\") else Path().resolve()\n",
    "DATA = BASE / \"data\" / \"practice\"\n",
    "print(\"DATA =\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde301ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) TSV — load with the correct delimiter, set 'date' as the index\n",
    "tsv_path = DATA / \"tsv\" / \"air_quality.tsv\"\n",
    "# TODO: df = pd.read_csv(...)\n",
    "# TODO: df.set_index(\"date\", inplace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) JSON — expand attendees to one row per person\n",
    "json_path = DATA / \"json\" / \"events.json\"\n",
    "# TODO: with open(json_path) as f: obj = json.load(f)\n",
    "# TODO: from pandas import json_normalize\n",
    "# TODO: flat = json_normalize(obj, record_path=\"attendees\", meta=[\"event\",\"when\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Plain text — count ERROR lines\n",
    "log_path = DATA / \"text\" / \"log.txt\"\n",
    "# TODO: with open(log_path) as f: lines = f.readlines()\n",
    "# TODO: error_count = sum(1 for ln in lines if \"ERROR\" in ln)\n",
    "# error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) HTML — read all tables and select the one with id='awards'\n",
    "html_path = DATA / \"html\" / \"wiki_table.html\"\n",
    "# TODO: tables = pd.read_html(str(html_path))\n",
    "# TODO: awards = tables[0]  # there's only one table in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa640ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Compressed CSV — read gzipped file and compute mean rating\n",
    "gz_path = DATA / \"csv_gz\" / \"movies.csv.gz\"\n",
    "# TODO: df = pd.read_csv(gz_path, compression=\"gzip\")\n",
    "# TODO: df[\"imdb_rating\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) (Optional) Excel — join two sheets on 'region'\n",
    "excel_path = DATA / \"excel\" / \"sales_regions.xlsx\"\n",
    "try:\n",
    "    q = pd.read_excel(excel_path, sheet_name=\"Quarterly\")\n",
    "    r = pd.read_excel(excel_path, sheet_name=\"Reps\")\n",
    "    # TODO: merged = q.merge(r, on=\"region\")\n",
    "except Exception as e:\n",
    "    print(\"Excel not available:\", e)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}